# What are protocol buffers

A mechanism to serialize `structured` data, in order to transfer it or storing it on disc,
kinda like json or xml but faster and smaller in size.
Proto buffers structure is defined in a .proto file which uses a similar syntax to typescript type definitions.

Protocol buffers are language agnostic and support a lot of object oriented languages. unfortunately js is not supported officially by google, but there are some open source tools to support it.

```proto
    syntax = "proto3"; // version

    message Employee {
    int32 id = 1;
    string name = 2;
    string department = 3;
    float salary = 4;
    }


    message Employees {
    repeated Employee employees = 1;
    }

```

# How to use

The code to serialize and deserialize is automatically generated by a compiler that takes as input the .proto file and the target language and outputs a the classes in the proto file

```shell
    protoc --java_out=. employee.proto
    protoc --python_out=[output dir] employee.proto
```

Js was supported by protoc until version 3.2 when google decided to make the js support its own project, but that is not moving forwards as of the time i'm typing this and there is no stable library.

### Protocol buffers serialization/deserialization in action

Running the previous commands will generate code for classes that contain method about creating objects, and methods for serialization and deserialization.

The python generated file is `employee_pb2.py`

```py
from operator import eq
import employee_pb2

emp = employee_pb2.Employee()

emp.id = 1
emp.name = "John Doe"
emp.department = "IT"
emp.salary = 1000


serialized = emp.SerializeToString()

print(serialized)
# prints b'\x08\x01\x12\x08John Doe\x1a\x02IT%\x00\x00zD'
# it can be persisted to non volatile storage or sent over the network, and it's way way smaller than json or xml or yaml..


emp2 = employee_pb2.Employee()
emp2.ParseFromString(serialized)
# ParseFromString() doesn't return anything, it fills in *self* with the parsed data

print(eq(emp, emp2))  # true

```

## Pros

- language agnostic
- backwards and forwards compatible
- can be extended with new information without invalidating existing data or requiring code to be updated
- fast parsing

## Cons

- The necessity to stick a schema,(Hussein nasser said that one of the reasons people moved from soap to json for not having to stick to a schema)

- not suited for large amounts of data, according to the docs, protocol buffers assume that all the data can be loaded into memory, other solutions should be considered when data exceeds a couple of mbs.

- Serialized buffers may not have the same binary serialization (think of it like password hashes with salt), so it's necessary to deserialize the data in order to compare it.

- protocol buffers messages are not self descriptive, we can't know much about them without the .proto file

- messages are not compressed.

## Where is it used

- the main format at google for inter-server communication as well as archival storage data on disk.
- grpc
- google cloud
- envoy proxy
